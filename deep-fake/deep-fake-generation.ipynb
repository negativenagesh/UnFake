{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:54<00:00,  7.73s/it]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from diffusers import StableDiffusionImg2ImgPipeline\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "# Load the pre-trained Stable Diffusion model\n",
    "model_id = \"runwayml/stable-diffusion-v1-5\"\n",
    "pipe = StableDiffusionImg2ImgPipeline.from_pretrained(model_id, torch_dtype=torch.float16)\n",
    "pipe = pipe.to(\"cuda\")  # Move the model to GPU for faster processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(image_path_or_url):\n",
    "    if image_path_or_url.startswith('http'):\n",
    "        response = requests.get(image_path_or_url)\n",
    "        image = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
    "    else:\n",
    "        image = Image.open(image_path_or_url).convert(\"RGB\")\n",
    "    return image\n",
    "\n",
    "input_image = load_image(\"/home/vu-lab03-pc24/deep-fake/images/shreeleela.jpg\")  \n",
    "width, height = input_image.size\n",
    "input_image = input_image.resize((width, height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:07<00:00,  4.63it/s]\n"
     ]
    }
   ],
   "source": [
    "# Define the prompt and parameters\n",
    "prompt = (\n",
    "    \"A highly detailed and realistic image of the person in the input image, \"\n",
    "    \"ultra-realistic, photorealistic, 8k resolution, intricate facial features, \"\n",
    "    \"natural skin texture, realistic hair, detailed eyes with reflections, \"\n",
    "    \"soft lighting, cinematic composition, professional portrait photography, \"\n",
    "    \"sharp focus, no artifacts, ultra-high quality, trending on ArtStation, Unreal Engine 5\"\n",
    ")\n",
    "\n",
    "negative_prompt = (\n",
    "   \"blurry, low quality, distorted, artifacts, cartoonish, unrealistic, oversaturated, overexposed, underexposed, bad anatomy, extra limbs, mutated hands, mutated fingers, deformed face, disfigured, poorly drawn face, poorly drawn hands, poorly drawn eyes, text, watermark, logo, signature, out of focus, grainy, pixelated, noisy, low resolution, ugly, unnatural lighting, flat, dull, oversmoothed, overprocessed\"\n",
    ")\n",
    "\n",
    "strength = 0.7  # Controls the influence of the input image on the output\n",
    "guidance_scale = 10.0  # Controls how closely the output follows the prompt\n",
    "\n",
    "# Generate the image\n",
    "with torch.autocast(\"cuda\"):\n",
    "    output_image = pipe(prompt=prompt, \n",
    "                    image=input_image, \n",
    "                    strength=strength, \n",
    "                    guidance_scale=guidance_scale, \n",
    "                    negative_prompt=negative_prompt\n",
    "                ).images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep fake image saved as 'shreeleela-deep_fake_output4.jpg'\n"
     ]
    }
   ],
   "source": [
    "output_image.save(\"shreeleela-deep_fake_output4.jpg\")\n",
    "print(\"Deep fake image saved as 'shreeleela-deep_fake_output4.jpg'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
